---
date: 2021-01-03T18:21
---

# model diagnostics

[[[regression]]]
[[ML]]
[[R]]
[[VIZ]]
[[Statistics]]


[Auditor package](https://modeloriented.github.io/auditor/articles/model_evaluation_audit.html) *See* vignettes for discussion.

``` r
suppressPackageStartupMessages({
  library(auditor)
  library(DALEX)
})

head(titanic_imputed)
#>   gender age class    embarked  fare sibsp parch survived
#> 1   male  42   3rd Southampton  7.11     0     0        0
#> 2   male  13   3rd Southampton 20.05     0     2        0
#> 3   male  16   3rd Southampton 20.05     1     1        0
#> 4 female  39   3rd Southampton 20.05     1     1        1
#> 5 female  16   3rd Southampton  7.13     0     0        1
#> 6   male  25   3rd Southampton  7.13     0     0        1

model_glm <- glm(survived ~ ., data = titanic_imputed, family = "binomial")

library(randomForest)
#> randomForest 4.6-14
#> Type rfNews() to see new features/changes/bug fixes.
model_rf <- randomForest(survived ~ ., data = titanic_imputed)
#> Warning in randomForest.default(m, y, ...): The response has five or fewer
#> unique values. Are you sure you want to do regression?

eva_glm <- model_evaluation(exp_glm)
#> Error in model_type %in% class(object): object 'exp_glm' not found
eva_rf <- model_evaluation(exp_rf)
#> Error in model_type %in% class(object): object 'exp_rf' not found

plot(eva_glm, eva_rf, type = "roc")
#> Error in plot(eva_glm, eva_rf, type = "roc"): object 'eva_glm' not found

plot(eva_glm, eva_rf, type = "lift")
#> Error in plot(eva_glm, eva_rf, type = "lift"): object 'eva_glm' not found

data(dragons)
head(dragons)
#>   year_of_birth   height   weight scars colour year_of_discovery
#> 1         -1291 59.40365 15.32391     7    red              1700
#> 2          1589 46.21374 11.80819     5    red              1700
#> 3          1528 49.17233 13.34482     6    red              1700
#> 4          1645 48.29177 13.27427     5  green              1700
#> 5            -8 49.99679 13.08757     1    red              1700
#> 6           915 45.40876 11.48717     2    red              1700
#>   number_of_lost_teeth life_length
#> 1                   25   1368.4331
#> 2                   28   1377.0474
#> 3                   38   1603.9632
#> 4                   33   1434.4222
#> 5                   18    985.4905
#> 6                   20    969.5682

# Linear regression
lm_model <- lm(life_length ~ ., data = dragons)

# Random forest
library(randomForest)
set.seed(59)
rf_model <- randomForest(life_length ~ ., data = dragons)

lm_exp <- DALEX::explain(lm_model, label = "lm", data = dragons, y = dragons$life_length)
#> Preparation of a new explainer is initiated
#>   -> model label       :  lm 
#>   -> data              :  2000  rows  8  cols 
#>   -> target variable   :  2000  values 
#>   -> predict function  :  yhat.lm  will be used ( [33m default [39m )
#>   -> predicted values  :  numerical, min =  540.9447 , mean =  1370.986 , max =  3925.691  
#>   -> model_info        :  package stats , ver. 4.0.2 , task regression ( [33m default [39m ) 
#>   -> residual function :  difference between y and yhat ( [33m default [39m )
#>   -> residuals         :  numerical, min =  -108.2062 , mean =  -3.700842e-12 , max =  113.8603  
#>  [32m A new explainer has been created! [39m
rf_exp <- DALEX::explain(rf_model, label = "rf", data = dragons, y = dragons$life_length)
#> Preparation of a new explainer is initiated
#>   -> model label       :  rf 
#>   -> data              :  2000  rows  8  cols 
#>   -> target variable   :  2000  values 
#>   -> predict function  :  yhat.randomForest  will be used ( [33m default [39m )
#>   -> predicted values  :  numerical, min =  610.9752 , mean =  1370.181 , max =  3292.296  
#>   -> model_info        :  package randomForest , ver. 4.6.14 , task regression ( [33m default [39m ) 
#>   -> residual function :  difference between y and yhat ( [33m default [39m )
#>   -> residuals         :  numerical, min =  -135.4756 , mean =  0.8047108 , max =  720.0888  
#>  [32m A new explainer has been created! [39m

library(auditor)
lm_mr <- model_residual(lm_exp)
rf_mr <- model_residual(rf_exp)

plot(rf_mr, lm_mr, type = "prediction", abline = TRUE)
```

![](https://i.imgur.com/JWkJFdl.png)

``` r
# alternatives:
# plot_prediction(rf_mr, lm_mr, abline = TRUE)
# plot_prediction(rf_mr, lm_mr, variable = "life_length")

plot(rf_mr, lm_mr, variable = "scars", type = "prediction")
```

![](https://i.imgur.com/X6k9y1r.png)

``` r
plot(rf_mr, lm_mr, variable = "height", type = "prediction")
```

![](https://i.imgur.com/iJXjRKx.png)

``` r
plot(lm_mr, rf_mr, type = "residual")
```

![](https://i.imgur.com/JWSgLwo.png)

``` r
# alternative:
# plot_residual(lm_mr, rf_mr)

plot(rf_mr, lm_mr, type = "residual", variable = "_y_hat_")
```

![](https://i.imgur.com/AK84EFc.png)

``` r
plot(rf_mr, lm_mr, type = "residual", variable = "scars")
```

![](https://i.imgur.com/5k6FPVf.png)

``` r
# alternative:
# plot_residual(rf_mr, lm_mr, variable = "_y_hat_")
# plot_residual(rf_mr, lm_mr, variable = "scars")

plot_residual(rf_mr, variable = "_y_hat_", nlabel = 10)
```

![](https://i.imgur.com/ivp49EV.png)

``` r
plot(rf_mr, lm_mr, type = "residual_density")
```

![](https://i.imgur.com/lnMPoqh.png)

``` r
# alternative
# plot_residual_density(rf_mr, lm_mr)

plot(lm_mr, rf_mr, type = "residual_boxplot")
```

![](https://i.imgur.com/TP3NcDf.png)

``` r
# alternative
# plot_residual_boxplot(lm_mr, rf_mr)

plot(lm_mr, type = "acf", variable = "year_of_discovery")
```

![](https://i.imgur.com/GcBMASg.png)

``` r
# alternative:
# plot_acf(lm_mr, variable = "year_of_discovery")


plot(rf_mr, type = "autocorrelation")
```

![](https://i.imgur.com/aKiSiyv.png)

``` r
# alternative:
# plot_autocorrelation(rf_mr)

score_dw(rf_exp)$score
#> [1] 1.951918
score_runs(rf_exp)$score
#> [1] -1.881788

plot(rf_mr, lm_mr, type = "correlation")
```

![](https://i.imgur.com/F4Ym006.png)

``` r
plot(rf_mr, lm_mr, type = "pca")
```

![](https://i.imgur.com/QLYOAtG.png)

``` r
# alternative:
# plot_pca(rf_mr, lm_mr)

plot(rf_mr, lm_mr, type = "rec")
```

![](https://i.imgur.com/2pd9kaI.png)

``` r
# alternative:
# plot_rec(rf_mr, lm_mr)

plot(rf_mr, lm_mr, type = "rroc")
```

![](https://i.imgur.com/K4dp23J.png)

``` r
plot(rf_mr, lm_mr, type = "scalelocation")
```

![](https://i.imgur.com/40tQEzZ.png)

``` r
# alternative:
# plot_scalelocation(rf_mr, lm_mr)

plot(rf_mr, lm_mr, type = "tsecdf")
```

![](https://i.imgur.com/1v5odus.png)

``` r
# alternative
# plot_tsecdf(rf_mr, lm_mr)

# Linear regression
lm_model <- lm(life_length ~ ., data = dragons)

# Random forest


rf_model <- randomForest(life_length ~ ., data = dragons)
lm_exp <- DALEX::explain(lm_model, label = "lm", data = dragons, y = dragons$life_length)
#> Preparation of a new explainer is initiated
#>   -> model label       :  lm 
#>   -> data              :  2000  rows  8  cols 
#>   -> target variable   :  2000  values 
#>   -> predict function  :  yhat.lm  will be used ( [33m default [39m )
#>   -> predicted values  :  numerical, min =  540.9447 , mean =  1370.986 , max =  3925.691  
#>   -> model_info        :  package stats , ver. 4.0.2 , task regression ( [33m default [39m ) 
#>   -> residual function :  difference between y and yhat ( [33m default [39m )
#>   -> residuals         :  numerical, min =  -108.2062 , mean =  -3.700842e-12 , max =  113.8603  
#>  [32m A new explainer has been created! [39m
rf_exp <- DALEX::explain(rf_model, label = "rf", data = dragons, y = dragons$life_length)
#> Preparation of a new explainer is initiated
#>   -> model label       :  rf 
#>   -> data              :  2000  rows  8  cols 
#>   -> target variable   :  2000  values 
#>   -> predict function  :  yhat.randomForest  will be used ( [33m default [39m )
#>   -> predicted values  :  numerical, min =  626.4623 , mean =  1370.347 , max =  3320.745  
#>   -> model_info        :  package randomForest , ver. 4.6.14 , task regression ( [33m default [39m ) 
#>   -> residual function :  difference between y and yhat ( [33m default [39m )
#>   -> residuals         :  numerical, min =  -151.715 , mean =  0.6389129 , max =  709.8066  
#>  [32m A new explainer has been created! [39m
lm_cd <- model_cooksdistance(lm_exp)
plot(lm_cd)
```

![](https://i.imgur.com/D2d4gOp.png)

``` r
 

data(corn, package = "hnp")
head(corn)
#>   extract  m  y
#> 1    leaf 35 26
#> 2    leaf 36 25
#> 3    leaf 38 21
#> 4    leaf 38 18
#> 5    leaf 39 30
#> 6    leaf 38  8
set.seed(123)
model_bin <- glm(cbind(y, m - y) ~ extract, family = binomial, data = corn)
bin_exp <- DALEX::explain(model_bin, data = corn, y = corn$y)
#> Preparation of a new explainer is initiated
#>   -> model label       :  lm  ( [33m default [39m )
#>   -> data              :  40  rows  3  cols 
#>   -> target variable   :  40  values 
#>   -> predict function  :  yhat.glm  will be used ( [33m default [39m )
#>   -> predicted values  :  numerical, min =  0.01133144 , mean =  0.5133687 , max =  0.8148148  
#>   -> model_info        :  package stats , ver. 4.0.2 , task classification ( [33m default [39m ) 
#>   -> residual function :  difference between y and yhat ( [33m default [39m )
#>   -> residuals         :  numerical, min =  -0.01133144 , mean =  17.96163 , max =  34.18519  
#>  [32m A new explainer has been created! [39m


bin_hnp <- model_halfnormal(bin_exp)
#> Binomial model

plot(bin_hnp, sim = 500)
```

![](https://i.imgur.com/noZ3y96.png)

``` r
# or
# plot_halfnormal(bin_hnp, sim = 500)


plot(bin_hnp, quantiles = TRUE)
```

![](https://i.imgur.com/hUoNJ7H.png)

``` r
library(randomForest)
iris_rf <- randomForest(Species ~ ., data = iris)
iris_rf_exp <- DALEX::explain(iris_rf, data = iris, y = as.numeric(iris$Species) - 1)
#> Preparation of a new explainer is initiated
#>   -> model label       :  randomForest  ( [33m default [39m )
#>   -> data              :  150  rows  5  cols 
#>   -> target variable   :  150  values 
#>   -> predict function  :  yhat.randomForest  will be used ( [33m default [39m )
#>   -> predicted values  :  predict function returns multiple columns:  3  ( [33m default [39m ) 
#>   -> model_info        :  package randomForest , ver. 4.6.14 , task multiclass ( [33m default [39m ) 
#>   -> model_info        :  Model info detected multiclass task but 'y' is a numeric .  ( [31m WARNING [39m )
#>   -> model_info        :  By deafult classification tasks supports only factor 'y' parameter. 
#>   -> model_info        :  Consider changing to a factor vector with true class names.
#>   -> model_info        :  Otherwise I will not be able to calculate residuals or loss function.
#>   -> residual function :  difference between 1 and probability of true class ( [33m default [39m )
#>   -> residuals         :  the residual_function returns an error when executed ( [31m WARNING [39m ) 
#>  [32m A new explainer has been created! [39m
iris_rf_hnp <- model_halfnormal(iris_rf_exp)
plot_halfnormal(iris_rf_hnp)
```

![](https://i.imgur.com/tYM3lfN.png)
