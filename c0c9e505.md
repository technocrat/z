---
date: 2021-01-04T16:12
---

# Local Interpretable Model-agnostic Explanations

[[[ML]]]
[[script]]
[[lime]]
[[1cb81852]]

[source](https://medium.com/responsibleml/basic-xai-with-dalex-part-6-lime-method-f6aab0af058a)

> The objective is to find a local model M that approximates a black box model f around the point of interest xâ‚Š.

AKA "glass model" or "white-box model"

*Local* explanatory

> It approximates the black-box model around the instance of interest. 

selects K most important interpretable features

Unable to run example from [source](https://medium.com/responsibleml/basic-xai-with-dalex-part-6-lime-method-f6aab0af058a) or from [text](https://ema.drwhy.ai/LIME.html#LIME)


	library(lime)
    library(DALEX)
    library("DALEXtra")

    titanic_imputed <- archivist::aread("pbiecek/models/27e5c")
    titanic_rf <- archivist:: aread("pbiecek/models/4e0fc")
    johnny_d <- archivist:: aread("pbiecek/models/e3596")
    titanic_rf_exp <- DALEX::explain(model = titanic_rf,  
                                     data = titanic_imputed[, -9],
                                     y = titanic_imputed$survived == "yes", 
                                     label = "Random Forest")
    set.seed(1)
    model_type.dalex_explainer <- DALEXtra::model_type.dalex_explainer
    predict_model.dalex_explainer <- DALEXtra::predict_model.dalex_explainer
    lime_johnny <- predict_surrogate(explainer = titanic_rf_exp, 
                                     new_observation = johnny_d, 
                                     n_features = 3, 
                                     n_permutations = 1000,
                                     type = "lime")

    (as.data.frame(lime_johnny))
