---
date: 2021-01-04T01:11
---

# Text on explanatory model analysis

[[[ML]]]
[[CITE]]

[Exploratory Model Analysis](https://ema.drwhy.ai/)



@Book{,
  author = {Przemyslaw Biecek and Tomasz Burzykowski},
  title = {{Explanatory Model Analysis}},
  publisher = {Chapman and Hall/CRC, New York},
  year = {2021},
  isbn = {9780367135591},
  url = {https://pbiecek.github.io/ema/},
}


***Black box disambiguation***

> Machine learning, on the other hand, exploits the trade-off between the availability of data and domain knowledge. 

![](https://ema.drwhy.ai/figure/UMEPImportance.png)

> Summarizing, we can conclude that, today, the true bottleneck in predictive modelling is neither the lack of data, nor the lack of computational power, nor inadequate algorithms, nor the lack of flexible models. It is the lack of tools for model exploration and, in particular, model explanation (obtaining insight into model-based predictions) and model examination (evaluation of model’s performance and understanding the weaknesses).



* Prediction’s validation. For every prediction of a model, one should be able to verify how strong the evidence is that supports the prediction.
* Prediction’s justification. For every prediction of a model, one should be able to understand which variables affect the prediction and to what extent.
* Prediction’s speculation. For every prediction of a model, one should be able to understand how the prediction would change if the values of the variables included in the model changed.

Lingo guide:

> in the statistical-modelling literature, one refers to “explanatory variables”, with “independent variables”, “predictors”, or “covariates” often used as equivalents. Explanatory variables are used in a model as a means to explain (predict) the “dependent variable”, also called “predicted” variable or “response”. In machine-learning terminology, “input variables” or “features” are used to predict the “output” or “target” variable. In statistical modelling, models are “fit” to the data that contain “observations”, whereas in the machine-learning world a model is “trained” on a dataset that may contain “instances” or “cases”. When we talk about numerical constants that define a particular version of a model, in statistical modelling, we refer to model “coefficients”, while in machine learning it is more customary to refer to model “parameters”. In statistics, it is common to say that model coefficients are “estimated”, while in machine learning it is more common to say that parameters are “trained”.

> A “glass-box” (sometimes also called a “white-box” or a “transparent-box”) model, which is opposite to a black-box one, is a model that is easy to understand (though maybe not by every person). It has a simple structure and a limited number of 
coefficients.

> However, while we do not assume anything about the structure of the model, we will assume that the model operates on p-dimensional vector of explanatory variables/features and, for a single observation, it returns a single value (score/probability), which is a real number. This assumption holds for a broad range of models for data such as tabular data, images, text data, videos, etc. It may not be suitable for, e.g., models with memory-like sequence-to-sequence models (Sutskever, Vinyals, and Le 2014) or Long Short-Term Memory models (Hochreiter and Schmidhuber 1997) in which the model output depends also on sequence of previous inputs, or generative models that output text of images.

![](https://ema.drwhy.ai/figure/UMEPpiramide.png)